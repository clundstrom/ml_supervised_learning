{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. One versus all MNIST\n",
    "\n",
    "##### 1.1  Finding optimal hyperparameters for SVC with rbf kernel\n",
    "\n",
    "First the MNIST set is downloaded and split into a training set and a test set. The target set is converted to float.\n",
    "\n",
    "The training and test set are normalized in order to speed up training. (SVCs are sensitive to non normalized data).\n",
    "After that a grid search is performed over a number of hyperparameters in order to find the best pair for a subset\n",
    "of 1000 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# Fetch MNIST\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
    "X, y = mnist['data'], mnist['target']\n",
    "\n",
    "y = y.astype('float64')  # all y values are chars from the source for some reason..\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.2, random_state=10)\n",
    "\n",
    "# Normalize data to speed up training\n",
    "scaler = pp.StandardScaler().fit(X_train)\n",
    "Xn_train = scaler.transform(X_train)\n",
    "Xn_test = scaler.transform(X_test)\n",
    "\n",
    "# Instantiate SVC\n",
    "rbf = SVC(kernel='rbf', gamma=.001, C=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1.2 Fit data to training set and calculate score on test set.\n",
    "\n",
    "After training the score will yield an accuracy of 88.2% (0.8820714285714286) on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search score:  0.8828571428571429\n",
      "{'C': 2, 'gamma': 0.001}\n",
      "Test Accuracy:  0.8820714285714286\n",
      "[[1347    1   23    6    3   14    8    3   16    0]\n",
      " [   0 1469   14    3    0    2    3    2   22    0]\n",
      " [  16   20 1279   12   36    4   13   22   35    1]\n",
      " [   4   13  109 1213    2   34    6   16   35    4]\n",
      " [   3   10   39    1 1263    0    3    7    7   58]\n",
      " [  14   12   37   58    8 1034   31   10   28   16]\n",
      " [   7   18   66    0   18   17 1159    0   18    0]\n",
      " [   5   24   76    5   15    0    0 1314    4   30]\n",
      " [  24   40   58   30   13   65    6    3 1114   19]\n",
      " [  10    9   39   19   67    3    0   87   12 1157]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.95      0.94      1421\n",
      "         1.0       0.91      0.97      0.94      1515\n",
      "         2.0       0.74      0.89      0.80      1438\n",
      "         3.0       0.90      0.84      0.87      1436\n",
      "         4.0       0.89      0.91      0.90      1391\n",
      "         5.0       0.88      0.83      0.85      1248\n",
      "         6.0       0.94      0.89      0.92      1303\n",
      "         7.0       0.90      0.89      0.89      1473\n",
      "         8.0       0.86      0.81      0.84      1372\n",
      "         9.0       0.90      0.82      0.86      1403\n",
      "\n",
      "    accuracy                           0.88     14000\n",
      "   macro avg       0.89      0.88      0.88     14000\n",
      "weighted avg       0.89      0.88      0.88     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find good values for C and gamma.\n",
    "C = np.arange(1, 11, 1)\n",
    "gamma = np.arange(0.001, 0.01, 0.001)\n",
    "param_grid = {'C': C, 'gamma': gamma}\n",
    "grid_search = GridSearchCV(rbf, param_grid, scoring='accuracy', n_jobs=10)\n",
    "grid_search.fit(Xn_train[:1000, :], y_train[:1000])\n",
    "\n",
    "# Print training score and best params\n",
    "print(\"Grid search score: \", grid_search.score(Xn_train, y_train))\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "rbf = grid_search.best_estimator_\n",
    "print(\"Test Accuracy: \", rbf.score(Xn_test, y_test))\n",
    "\n",
    "pred_test = rbf.predict(Xn_test)\n",
    "\n",
    "print(confusion_matrix(y_test, pred_test))\n",
    "print(classification_report(y_test, pred_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 One versus All\n",
    "\n",
    "This next part compares One-Vs-One and One-Vs-All SVCs.\n",
    "\n",
    "**General Approach**: One-Vs-All works by training one classifier for each class.\n",
    "After training all classifiers one can predict a sample and compare the probabilistic results of the predictors.\n",
    "SVCs are not probabilistic in nature so they need to use Platt Scaling in order to return a result of that nature.\n",
    "\n",
    "The MNIST data set contains target values ranging from 0-9. By modifying the target values to either 1 or 0 for each classifier \n",
    "I can train a classifier to recognize only one number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Make hard copies for later binarization\n",
    "y_0 = np.copy(y_train)\n",
    "y_1 = np.copy(y_train)\n",
    "y_2 = np.copy(y_train)\n",
    "y_3 = np.copy(y_train)\n",
    "y_4 = np.copy(y_train)\n",
    "y_5 = np.copy(y_train)\n",
    "y_6 = np.copy(y_train)\n",
    "y_7 = np.copy(y_train)\n",
    "y_8 = np.copy(y_train)\n",
    "y_9 = np.copy(y_train)\n",
    "\n",
    "# Make classifications binary\n",
    "y_0[y_train != 0] = 1  # special case, inverse column of prediction for correct comparisons\n",
    "y_1[y_train != 1] = 0 # all numbers that arent 1, -> set to 0\n",
    "y_2[y_train != 2] = 0 # repeat\n",
    "y_3[y_train != 3] = 0\n",
    "y_4[y_train != 4] = 0\n",
    "y_5[y_train != 5] = 0\n",
    "y_6[y_train != 6] = 0\n",
    "y_7[y_train != 7] = 0\n",
    "y_8[y_train != 8] = 0\n",
    "y_9[y_train != 9] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All models have been trained on Xn_train in advance using the previous results of **gamma=0.001** and **c=2**.\n",
    "Training takes quite a while due to the large training set.\n",
    "\n",
    "Examples:\n",
    "\n",
    "zero_ = SVC(kernel='rbf', gamma=0.001, c=2, Probability=True).fit(Xn_train, y_0)\n",
    "one_ = SVC(kernel='rbf', gamma=0.001, c=2, Probability=True).fit(Xn_train, y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load SVCs\n",
    "zero_ = joblib.load('models/0.model')\n",
    "one_ = joblib.load('models/1.model')\n",
    "two_ = joblib.load('models/2.model')\n",
    "three_ = joblib.load('models/3.model')\n",
    "four_ = joblib.load('models/4.model')\n",
    "five_ = joblib.load('models/5.model')\n",
    "six_ = joblib.load('models/6.model')\n",
    "seven_ = joblib.load('models/7.model')\n",
    "eight_ = joblib.load('models/8.model')\n",
    "nine_ = joblib.load('models/9.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### 1.3 Predictions\n",
    "\n",
    "This next section predicts all rows of the test set and adds it to a list of predictions. The sum of errors\n",
    "and accuracy is calculated to **96.89%**\n",
    "\n",
    "#### Conclusions\n",
    "\n",
    "Accuracy wise the One-Vs-All approach is quite alot better at predictions than One-Vs-One but has a huge computational\n",
    "disadvantage in that it has to train 10 different models compared to One-Vs-One.\n",
    "\n",
    "Also it seems that One-Vs-All is better at predicting individual numbers when looking at the confusion matrix. Especially so for numbers 2, 5 and 8.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9689285714285715\n",
      "Errors: 435\n",
      "[[1402    0    4    0    0    2    6    3    4    0]\n",
      " [   0 1495    8    3    1    1    0    3    2    2]\n",
      " [   2    4 1379    9    5    2    4   15   15    3]\n",
      " [   2    0   11 1383    1    9    0   12   13    5]\n",
      " [   1    1    7    0 1340    1    7    4    5   25]\n",
      " [   3    3    0   10    0 1210    9    5    8    0]\n",
      " [   0    1    2    0    3   10 1280    2    5    0]\n",
      " [   2    8   13    3    8    1    1 1418    1   18]\n",
      " [   4    9    3    4    6    7    6    3 1325    5]\n",
      " [   3    3    3   11   14    5    0   23    8 1333]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      1421\n",
      "         1.0       0.98      0.99      0.98      1515\n",
      "         2.0       0.96      0.96      0.96      1438\n",
      "         3.0       0.97      0.96      0.97      1436\n",
      "         4.0       0.97      0.96      0.97      1391\n",
      "         5.0       0.97      0.97      0.97      1248\n",
      "         6.0       0.97      0.98      0.98      1303\n",
      "         7.0       0.95      0.96      0.96      1473\n",
      "         8.0       0.96      0.97      0.96      1372\n",
      "         9.0       0.96      0.95      0.95      1403\n",
      "\n",
      "    accuracy                           0.97     14000\n",
      "   macro avg       0.97      0.97      0.97     14000\n",
      "weighted avg       0.97      0.97      0.97     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.array([])\n",
    "# Predict all rows\n",
    "\n",
    "for row in Xn_test:\n",
    "    probs = np.array([zero_.predict_proba(row.reshape(1, -1))[0, 0]]) # special case, probability column is inverted\n",
    "    probs = np.append(probs, [one_.predict_proba(row.reshape(1, -1))[0, 1]])\n",
    "    probs = np.append(probs, [two_.predict_proba(row.reshape(1, -1))[0, 1]])\n",
    "    probs = np.append(probs, [three_.predict_proba(row.reshape(1, -1))[0, 1]])\n",
    "    probs = np.append(probs, [four_.predict_proba(row.reshape(1, -1))[0, 1]])\n",
    "    probs = np.append(probs, [five_.predict_proba(row.reshape(1, -1))[0, 1]])\n",
    "    probs = np.append(probs, [six_.predict_proba(row.reshape(1, -1))[0, 1]])\n",
    "    probs = np.append(probs, [seven_.predict_proba(row.reshape(1, -1))[0, 1]])\n",
    "    probs = np.append(probs, [eight_.predict_proba(row.reshape(1, -1))[0, 1]])\n",
    "    probs = np.append(probs, [nine_.predict_proba(row.reshape(1, -1))[0, 1]])\n",
    "    index = probs.argmax()\n",
    "    y_pred = np.append(y_pred, index)\n",
    "\n",
    "\n",
    "errors = np.sum(y_pred != y_test)\n",
    "print(\"Accuracy: \", 1- (errors/len(Xn_test)))\n",
    "print(\"Errors:\" , errors)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
