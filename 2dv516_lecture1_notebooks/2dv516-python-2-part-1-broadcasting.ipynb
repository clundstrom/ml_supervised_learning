{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from timeit import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We talked a lot about `numpy` vectorization in the previous lecture. Just as a quick recap, a vectorized operation is a math operation that is applied directly to vectors, such as the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 10, 18])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "y = np.array([4, 5, 6])\n",
    "z = x * y\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, each element of $x$ was multiplied with each *corresponding* element of $y$ to form $z$, that is: $z_i = x_i * y_i$. That was easy for `numpy` because $x$ and $y$ have the exact same shape, so there was no ambiguity as to which element should be multiplied by which. \n",
    "\n",
    "Whenever two arrays have the exact same shape, it is usually possible to apply vectorized operations such as this one. Vectorized operations are always much faster than their equivalent implementation with Python loops, because `numpy` operations are implemented in native code. \n",
    "\n",
    "Check the results of the cell below for a very simple benchmark of two different implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized: 0.007251740999890899 seconds\n",
      "Loop: 4.252399514999979 seconds\n",
      "---\n",
      "Loop version was 586.3970479728875 times slower.\n"
     ]
    }
   ],
   "source": [
    "def mult_vect(x, y):\n",
    "    return x * y\n",
    "\n",
    "def mult_loop(x, y):\n",
    "    z = np.empty(x.shape)\n",
    "    for i in range(x.shape[0]):\n",
    "        z[i] = x[i] * y[i]\n",
    "    return z\n",
    "\n",
    "x = np.random.rand(100000)\n",
    "y = np.random.rand(100000)\n",
    "\n",
    "# Make sure the results are exactly the same\n",
    "assert np.all(mult_vect(x, y) == mult_loop(x, y))\n",
    "\n",
    "t_fast = timeit(lambda: mult_vect(x, y), number=100)\n",
    "print(f\"Vectorized: {t_fast} seconds\")\n",
    "\n",
    "t_slow = timeit(lambda: mult_loop(x, y), number=100)\n",
    "print(f\"Loop: {t_slow} seconds\")\n",
    "\n",
    "print('---')\n",
    "\n",
    "print(f\"Loop version was {t_slow / t_fast} times slower.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Broadcasting** is a special type of vectorization that is available in Numpy. We already saw this before, but did not discuss it in details. Consider the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 50, 100, 150])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([5, 10, 15])\n",
    "y = 10\n",
    "z = x * y\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that $x$, which is a vector of shape `3`, was successfully multiplied with $y$, which is a number, even though they do not have the same \"shape\". That is because $y$ was *implicitly* extended to match $x$'s shape (only implicitly; it was not copied in memory for that): $y' = \\begin{bmatrix} y & y & y \\end{bmatrix}$. As soon as both vectors have the same shape (even if only *implicitly*), then vectorized operations can be applied as usual: $z_i = x_i * y_i$.\n",
    "\n",
    "In other words, you can think that $y$ was *broadcasted* to the shape of $x$ in order to obtain $z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the slightly more complex example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  7, 13],\n",
       "       [ 5, 10, 16]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [1, 2, 3], \n",
    "    [4, 5, 6]])\n",
    "\n",
    "y = np.array([1, 5, 10])\n",
    "\n",
    "X + y    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the vector $y$, which is of shape `3`, was summed with each row of the matrix $X$, which is of shape `(2,3)`. As with the previous example, $y$ was implicitly extended to match $X$'s shape (again, only implicitly, it is not duplicated in memory): $y' = \\begin{bmatrix} 1 & 5 & 10 \\\\ 1 & 5 & 10 \\end{bmatrix}$. The extended version of $y$ ($y'$) can then be directly summed with $X$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the situation above was relatively easy for `numpy`, as there was very little ambiguity in the code regarding which values should be multiplied against which. Given that broadcast is available, it was more-or-less straightforward to decide how to extend $y$. \n",
    "\n",
    "The code below, however, although almost identical, results in an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,2) (3,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ca80848ac9a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     [3, 6]])\n\u001b[1;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,2) (3,) "
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [1, 4], \n",
    "    [2, 5],\n",
    "    [3, 6]])\n",
    "y = np.array([1, 5, 10])\n",
    "X + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the shape of $X$ is `(3,2)`, which is not compatible with the shape of $y$, which is `3`. Contrary to what is common in algebra books, `numpy` considers $y$ as a *row* vector (with 3 columns), not a *column* vector. Thus, it is not possible to broadcast $y$ into the shape of $X$ in a straightforward manner, because $y$ has 3 columns while $X$ has only two.\n",
    "\n",
    "If you had written the code above, most probably what you wanted was to broadcast $y$ over the columns of $X$. The code below achieves that by reshaping $y$ into a column vector. After that, `numpy` can extend $y$ into a matrix of shape `(3,2)` and the operation is applied as usual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  5],\n",
       "       [ 7, 10],\n",
       "       [13, 16]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X + y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting is not only a way to write clean and shorter code; it has the speed advantages of vectorized code. In other words, writing code with `numpy` broadcasting is almost the same as replacing slow Python loops with native, compiled versions. Check the benchmark below for a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized: 0.05051784499983114 seconds\n",
      "Loop + Vectorized: 3.69278195600009 seconds\n",
      "Loop: 16.166654963999918 seconds\n",
      "---\n",
      "Loop+Vect version was 73.09856459657836 times slower.\n",
      "Loop version was 320.0186976315786 times slower.\n"
     ]
    }
   ],
   "source": [
    "def mult_vect(X, y):\n",
    "    return X * y\n",
    "\n",
    "def mult_loop_vect(X, y):\n",
    "    Z = np.empty(X.shape)\n",
    "    for i in range(X.shape[0]):\n",
    "        Z[i,:] = X[i,:] * y\n",
    "    return Z\n",
    "\n",
    "def mult_loop(X, y):\n",
    "    Z = np.empty(X.shape)\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            Z[i, j] = X[i, j] * y[j]\n",
    "    return Z\n",
    "\n",
    "X = np.random.rand(30000, 10)\n",
    "y = np.random.rand(10)\n",
    "\n",
    "# Make sure the results are exactly the same\n",
    "assert np.all(mult_vect(X, y) == mult_loop_vect(X, y))\n",
    "assert np.all(mult_vect(X, y) == mult_loop(X, y))\n",
    "\n",
    "t_fast = timeit(lambda: mult_vect(X, y), number=100)\n",
    "print(f\"Vectorized: {t_fast} seconds\")\n",
    "\n",
    "t_slow = timeit(lambda: mult_loop_vect(X, y), number=100)\n",
    "print(f\"Loop + Vectorized: {t_slow} seconds\")\n",
    "\n",
    "t_very_slow = timeit(lambda: mult_loop(X, y), number=100)\n",
    "print(f\"Loop: {t_very_slow} seconds\")\n",
    "\n",
    "print('---')\n",
    "\n",
    "print(f\"Loop+Vect version was {t_slow / t_fast} times slower.\")\n",
    "print(f\"Loop version was {t_very_slow / t_fast} times slower.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are some rules as to which shapes can be broadcasted together. In order to check if two shapes are compatible for broadcasting, you have to look at each pair of axes, from the last to the first. They are compatible if (a) they are the same, or (b) one of them is `1`. If an axes is not present, you can consider it as `1`. \n",
    "\n",
    "**Example:** In the benchmark above, the shapes are `(30000, 10)` and `10`. Starting with the last pair of axes, they are compatible because they are the same (both are `10`). For the next pair, one is `30000` and the other is not present, so we consider it as `1`. Thus, they are also compatible.\n",
    "\n",
    "**Example:** In the example above where an error was raised, the two shapes were `(3,2)` and `3`. The last pair of axes are not compatible, since one is `2` and the other is `3`. That means the shapes are not compatible, so you cannot use broadcasting here.\n",
    "\n",
    "This is flexible enough to lead to some potentially very abstract and crazy broadcasting operations, which might not be very easy to read and understand. If you want to start using broadcasting in the simplest way possible, at least until you are more experienced, look at the examples above where a row/column vector is broadcasted over all the rows/columns of a matrix. This will get you a long way with the minimum effort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Euclidean Distance Matrix\n",
    "\n",
    "Many machine learning algorithms require a distance matrix as input, containing all pairwise distances (usually Euclidean) between all the instances from a data set. Computing such a matrix is a quadratic (and potentially slow) operation, especially if you are not optimizing it in any way.\n",
    "\n",
    "The code below shows a performance comparison between several possible implementations to obtain such a distance matrix. They get faster and faster towards the end, but also more complex and harder to read. The last one has completely removed all loops from the code, at the expense of being almost unreadable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop1: 4.251271112000268 seconds\n",
      "loop2: 2.129798750000191 seconds\n",
      "The loop version is 1.9960905282716908 times slower.\n",
      "broadcast1: 0.016913295999984257 seconds\n",
      "The loop version is 251.3567498614241 times slower.\n",
      "broadcast2: 0.01631018199987011 seconds\n",
      "The loop version is 260.6513595025564 times slower.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01631018199987011"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# Our dataset: 500 instances with 10 features each, all random\n",
    "X = np.random.rand(500, 10)\n",
    "\n",
    "# The euclidean distance between two vectors, non-optimized\n",
    "def eucl_dist(x, y):\n",
    "    z = np.empty(x.shape)\n",
    "    for i in range(x.shape[0]):\n",
    "        z[i] = (x[i] - y[i])**2\n",
    "    return np.sqrt(np.sum(z))\n",
    "\n",
    "def loop1(X):\n",
    "    n = X.shape[0]\n",
    "    Z = np.empty((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            Z[i, j] = eucl_dist(X[i], X[j])\n",
    "    return Z\n",
    "\n",
    "# Euclidean distance itself is vectorized, but computing the matrix is still slow\n",
    "def loop2(X):\n",
    "    n = X.shape[0]\n",
    "    Z = np.empty((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            Z[i, j] = np.sqrt(np.sum((X[i] - X[j])**2))\n",
    "    return Z\n",
    "\n",
    "# Broadcast 1\n",
    "def broadcast1(X):\n",
    "    n = X.shape[0]\n",
    "    Z = np.empty((n, n))\n",
    "    for i in range(n):        \n",
    "        Z[i] = np.sqrt(np.sum((X[i] - X)**2, axis=-1))\n",
    "    return Z\n",
    "\n",
    "# Broadcast 2\n",
    "def broadcast2(X):\n",
    "    m, n = X.shape\n",
    "    Z = np.sqrt(np.sum((X.reshape(m, 1, n) - X.reshape(1, m, n))**2, axis=-1))\n",
    "    return Z\n",
    "\n",
    "# Baseline: Scipy implementation\n",
    "Z1 = squareform(pdist(X))\n",
    "\n",
    "def check(Z):\n",
    "    # Z1 is accessible, even though it is outside of the function!\n",
    "    assert np.allclose(Z, Z1)\n",
    "\n",
    "# Making sure all results are correct and equivalent\n",
    "#check(loop1(X))\n",
    "#check(loop2(X))\n",
    "#check(broadcast1(X))\n",
    "#check(broadcast2(X))\n",
    "\n",
    "\n",
    "# Performance\n",
    "\n",
    "def perf(func, t0=None):\n",
    "    # Passing a function into a function! :)\n",
    "    t = timeit(lambda: func(X), number=1)\n",
    "    print(f\"{func.__name__}: {t} seconds\")\n",
    "    if t0:\n",
    "        print(f\"The loop version is {t0 / t} times slower.\")\n",
    "    return t\n",
    "\n",
    "# Baseline: slowest implementation\n",
    "t1 = perf(loop1)\n",
    "\n",
    "perf(loop2, t1)\n",
    "perf(broadcast1, t1)\n",
    "perf(broadcast2, t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
