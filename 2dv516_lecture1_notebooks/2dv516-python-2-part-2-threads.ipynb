{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import random\n",
    "from timeit import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel processing is, in general, the act of running several tasks of your code simultaneously. Nowadays, most computers have multiple processing cores, and not using them feels like a waste of resources. Sometimes, more expensive servers (that can be rented in the cloud, for example) can have hundreds or even thousands of processors available at the same time.\n",
    "\n",
    "Depending on the circumstances, the act of turning your sequential code into a parallel version can be quite straightforward, and will involve simply breaking your operations down into well-defined *chunks*. However, it is not always that simple. If we are not careful, parallel processing can lead to a lot of unexpected behavior, especially if multiple parallel tasks are accessing and modifying the same objects. It is almost impossible to predict the exact order in which parallel tasks will be executed, because of many external factors.\n",
    "\n",
    "**In this lecture we will treat only the easy cases, that is, when the tasks running in paralell do not affect each other.** Other more complicated cases are out of scope for now and require much more study and work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embarassingly Parallel\n",
    "\n",
    "When a problem, that is originally sequential, can be easily turned into a parallel version with little or no extra effort, it is known as an *embarassingly parallel* problem. This is the case when the tasks that are going to be executed simultaneously have little or no dependency between each other.\n",
    "\n",
    "Let's revisit our example of the Euclidean distance between two vectors $x$ and $y$, this time in pure Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def eucl_dist(x, y):\n",
    "    #e = []\n",
    "    #for i in range(len(x)):\n",
    "    #    e.append((x[i] - y[i])**2)\n",
    "    #return sqrt(sum(e))\n",
    "    \n",
    "    # Alternative, shorter implementation:\n",
    "    return sqrt(sum([(x_ - y_)**2 for x_, y_ in zip(x, y)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we discussed before, we commonly need the full pairwise distance matrix between all vectors (or rows) of a dataset $X$. The implementation below is in pure Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_square_matrix(n):    \n",
    "    D = []\n",
    "    for i in range(n):\n",
    "        row = []\n",
    "        for j in range(n):\n",
    "            row.append(0)\n",
    "        D.append(row)\n",
    "    return D    \n",
    "\n",
    "def eucl_dist_matrix(X):\n",
    "    n = len(X)\n",
    "    # Initialize D as empty square list of lists, with len(x) rows/columns\n",
    "    D = empty_square_matrix(n)\n",
    "    # Fill D with the actual pairwise distances\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            D[i][j] = eucl_dist(X[i], X[j])\n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation is inherently sequential and quadratic, processing each possible (unordered) pair of rows from the dataset $X$ *twice*. The result is a list of lists $D$, such that $D[10][15]$, for example, contains the distance between rows $10$ and $15$ from the original dataset $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_iris: (150, 4)\n",
      "Shape of D_iris: (150, 150)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7874007874011812"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "X_iris = load_iris().data\n",
    "print(\"Shape of X_iris:\", X_iris.shape)\n",
    "\n",
    "# So far, our implementation is still in pure Python\n",
    "D_iris = eucl_dist_matrix(X_iris)\n",
    "print(f\"Shape of D_iris: ({len(D_iris)}, {len(D_iris[0])})\")\n",
    "\n",
    "# 'pdist' is a scipy function to calculate pairwise distances.\n",
    "# We use it here to check if our implementation is correct.\n",
    "D_pdist = squareform(pdist(X_iris))\n",
    "assert np.allclose(D_iris, D_pdist)\n",
    "\n",
    "D_iris[10][15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is right now, this pure-Python implementation is very slow. For the `iris` dataset it is not so bad, but as soon as we get to even a thousand points, it becomes quite a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris: 0.12969236400022055\n",
      "1000 random 100D points: 14.68535031600004\n"
     ]
    }
   ],
   "source": [
    "# Note: A 'lambda' is equivalent to an anonymous, inline function\n",
    "print(\"Iris:\", timeit(lambda: eucl_dist_matrix(X_iris), number=1))\n",
    "\n",
    "def random_dataset(m, n):\n",
    "    X_rnd = []\n",
    "    for i in range(m):\n",
    "        row = []\n",
    "        X_rnd.append(row)\n",
    "        for j in range(n):\n",
    "            row.append(random.random())\n",
    "    return X_rnd\n",
    "    # Alternative, shorter implementation:\n",
    "    #return [[random.random() for _ in range(n)] for _ in range(m)]\n",
    "\n",
    "X_rnd = random_dataset(1000, 100)\n",
    "\n",
    "print(\"1000 random 100D points:\", timeit(lambda: eucl_dist_matrix(X_rnd), number=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, obviously, one solution would be to reimplement this using Numpy (as we did in Part 1). We will get to that again soon, but first let's try something different. This problem can be seen as an *embarassingly parallel* problem: each cell, row, or column of the matrix $D$ can be computed independently, in any order, and the results will still be the same. \n",
    "\n",
    "See the example below for a demonstration of this. It is almost identical to the previous function, but this time the rows and columns ($i$ and $j$) are computed in a random sequence. The result is identical to the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eucl_dist_matrix_shuffled(X):\n",
    "    n = len(X)\n",
    "    # Initialize D as empty list of lists\n",
    "    D = empty_square_matrix(n)\n",
    "    # Fill D with the actual pairwise distances\n",
    "    # This time, however, the rows and columns are filled in random order\n",
    "    for i in random.sample(range(n), k=n):\n",
    "        for j in random.sample(range(n), k=n):\n",
    "            D[i][j] = eucl_dist(X[i], X[j])\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_iris_shf = eucl_dist_matrix_shuffled(X_iris)\n",
    "\n",
    "assert np.allclose(D_iris, D_iris_shf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threads vs. Processes\n",
    "\n",
    "There are, in general, two different ways to run tasks in parallel (in most programming languages): using multiple **threads** or multiple **processes**. \n",
    "\n",
    "**Threads** (https://docs.python.org/3/library/threading.html) are separate execution contexts within a single program. Code running in one thread cannot (in general) access or see the resources from another thread. Even if you never explicitly manipulated threads, you always used at least one thread in every program you ever wrote: the main (and, most of the time, only) execution thread where your program is running. You can, however, start new threads to run specific parts of your code (like the chunks we created before). In general, they will run in parallel (but not always, as we'll see below). Threads are very lightweight, which means you can start new threads very efficiently, because they share a lot of the resources of the process that is running them.\n",
    "\n",
    "**Processes** (https://docs.python.org/3/library/multiprocessing.html) are different programs running in your computer, completely isolated from each other. For example, if you have a browser window and a terminal open, these are two different processes, each with its own memory and resources. Usually, whenever you run a Python script, you are running a single process: the Python interpreter that executes your code. You can, however, start new \"child\" processes to run specific parts of your code; in practice, you are basically starting a completely new interpreter. This is not as lightweight as threads, because you need to copy a lot of data from the parent process to the child (usually using the hard disk), and then back again after the child is done. \n",
    "\n",
    "In both cases, however, the workflow is quite similar: (1) break your problem into chunks, (2) start a new thread/process to execute each chunk, and (3) gather all the intermediate results and aggregate them to reach the final result. However, there are advantages and disadvantages for the two approaches, and in Python specifically, threads don't always work the way you'd expect them to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python threads and the GIL (Global Interpreter Lock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how you run a single thread to execute a single task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in a thread!\n",
      "x = 123\n",
      "The end.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "from threading import Thread\n",
    "\n",
    "\n",
    "# Warning: print is not thread-safe!\n",
    "def a_simple_function(x):\n",
    "    print(\"Running in a thread!\")\n",
    "    # Some (useful) time-consuming task that would be executed by the thread\n",
    "    sum(2 ** x for x in range(random.randint(10000, 20000)))\n",
    "    print(\"x =\", x)\n",
    "    \n",
    "t = Thread(target=a_simple_function, args=(123,))\n",
    "t.start()\n",
    "\n",
    "t.join()\n",
    "\n",
    "print(\"The end.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, if you don't use `join` to wait for the thread to end, you may get unexpected results, such as \"The end.\" being printed before \"x = 123\".\n",
    "\n",
    "A single thread is usually not very interesting, though. In the example below, we start several different threads at the same time. The random size of the operation in each thread will simulate the unexpected external factors that may affect the running time of each thread. You should never expect the threads to be executed in a specific sequence (unless you're using locks or other more advanced mechanisms, which we won't discuss here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in a thread!Running in a thread!\n",
      "Running in a thread!\n",
      "\n",
      "Running in a thread!Running in a thread!\n",
      "\n",
      "x = 0\n",
      "x =x = 4\n",
      " 1\n",
      "x = 2\n",
      "x = 3\n",
      "The end.\n"
     ]
    }
   ],
   "source": [
    "threads = []\n",
    "\n",
    "for i in range(5):\n",
    "    t = Thread(target=a_simple_function, args=(i,))\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(\"The end.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we have to `join` the threads if we want to make sure they are finished before we move on with the rest of the code. Nevertheless, you will probably still see some strange results with the `print` statements, since the threads are all running in parallel and there is a small random factor in each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to implement our multithreaded version of the euclidean distance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task to be run in parallel by each thread\n",
    "def task(D, X, i, j):\n",
    "    D[i][j] = eucl_dist(X[i], X[j])\n",
    "\n",
    "def eucl_dist_matrix_thr(X):\n",
    "    n = len(X)\n",
    "    # Initialize D as empty square list of lists, with len(x) rows/columns\n",
    "    D = empty_square_matrix(n)\n",
    "    # Fill D with the actual pairwise distances\n",
    "    threads = []\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            # Previous implementation:\n",
    "            #D[i][j] = eucl_dist(X[i], X[j])\n",
    "            t = Thread(target=task, args=(D, X, i, j))\n",
    "            t.start()\n",
    "            threads.append(t)\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now check the correctness and performance of our new implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4346309740003562\n",
      "7.8913885570000275\n"
     ]
    }
   ],
   "source": [
    "X_rnd = random_dataset(300, 100)\n",
    "\n",
    "D_rnd = eucl_dist_matrix(X_rnd)\n",
    "D_rnd_thr = eucl_dist_matrix_thr(X_rnd)\n",
    "\n",
    "assert np.allclose(D_rnd, D_rnd_thr)\n",
    "\n",
    "print(\"Original:\", timeit(lambda: eucl_dist_matrix(X_rnd), number=1))\n",
    "print(\"Threaded:\", timeit(lambda: eucl_dist_matrix_thr(X_rnd), number=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ouch.** Not only we did not get any improvement, we actually made it significantly slower. There are two main factors that caused this. First, starting threads is not \"free\". There is an overhead when you start a new thread, which is usually not a big deal (especially when compared with the overhead of starting a new process). However, in this case (with the `iris` dataset), we are starting $150 \\times 150 = 22500$ threads! It is a bit exaggerated. We fix this in the implementation below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task to be run in parallel by each thread\n",
    "def task_2(D, X, i):\n",
    "    for j in range(len(X)):\n",
    "        D[i][j] = eucl_dist(X[i], X[j])\n",
    "\n",
    "def eucl_dist_matrix_thr_2(X):\n",
    "    n = len(X)\n",
    "    # Initialize D as empty square list of lists, with len(x) rows/columns\n",
    "    D = empty_square_matrix(n)\n",
    "    # Fill D with the actual pairwise distances\n",
    "    threads = []\n",
    "    for i in range(n):\n",
    "        t = Thread(target=task_2, args=(D, X, i))\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this new version, we start \"only\" $n$ threads, one per row of $X$. Each thread then handles the generation of one entire row of $D$. Let's check the correctness and performance below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.349947126999723\n",
      "1.3732232420006767\n"
     ]
    }
   ],
   "source": [
    "X_rnd = random_dataset(300, 100)\n",
    "\n",
    "D_rnd = eucl_dist_matrix(X_rnd)\n",
    "D_rnd_thr_2 = eucl_dist_matrix_thr_2(X_rnd)\n",
    "\n",
    "assert np.allclose(D_rnd, D_rnd_thr_2)\n",
    "\n",
    "print(timeit(lambda: eucl_dist_matrix(X_rnd), number=1))\n",
    "print(timeit(lambda: eucl_dist_matrix_thr_2(X_rnd), number=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this is not wonderful, but at least we got rid of the massive slowdown that we had before. **The lesson to learn here is:** threads are not free, so there must be a balance between the number of threads you start and the complexity of the task that each thread is executing. Too many lightweight threads may generate a significant overhead.\n",
    "\n",
    "However, we still did not get any improvement. In fact, we basically had the exact same performance, plus a very small overhead for the threads. Why is that? Because of the infamous **Global Intepreter Lock, or GIL**. We're not getting into details here about the GIL and why it exists (trust me, you wouldn't enjoy it). Suffice to say, **the GIL only allows one thread to be executed at any given time** in the Python interpreter. That is, even though the threads are independent, only one is executed at a time. Yes, that means **the GIL does not allow threads be run in parallel**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick detour: Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Process API is almost identical to the Thread, but with a few important caveats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "\n",
    "# Task to be run in parallel by each process\n",
    "def task_p(D, X, k, chunk_size):\n",
    "    for i in range(k, min(k+chunk_size, len(X))):\n",
    "        for j in range(len(X)):\n",
    "            D[i][j] = eucl_dist(X[i], X[j])\n",
    "\n",
    "def eucl_dist_matrix_p(X):\n",
    "    n = len(X)\n",
    "    # Initialize D as empty square list of lists, with len(x) rows/columns\n",
    "    D = empty_square_matrix(n)\n",
    "    # Fill D with the actual pairwise distances\n",
    "    threads = []\n",
    "    chunk_size = n // 8\n",
    "    for i in range(0, n, chunk_size):\n",
    "        t = Process(target=task_p, args=(D, X, i, chunk_size))\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4877c8a9d556>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_rnd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m700\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#D_rnd = eucl_dist_matrix(X_rnd)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#D_rnd_p = eucl_dist_matrix_p(X_rnd)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "X_rnd = random_dataset(700, 100)\n",
    "\n",
    "#D_rnd = eucl_dist_matrix(X_rnd)\n",
    "#D_rnd_p = eucl_dist_matrix_p(X_rnd)\n",
    "\n",
    "#assert np.allclose(D_rnd, D_rnd_p)\n",
    "\n",
    "print(timeit(lambda: eucl_dist_matrix(X_rnd), number=1))\n",
    "print(timeit(lambda: eucl_dist_matrix_p(X_rnd), number=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above will not work because of how the data is passed between processes. After $D$ is passed down to the child subprocess, it is never sent back to the parent one. For that you need some special *shared* objects. We will not get into that today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to threads\n",
    "\n",
    "So, why did we do all this? Is multithreading useless in Python? **No.** See the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task to be run in parallel by each thread\n",
    "def task_3(D, X, i):\n",
    "    D[i] = np.sqrt(np.sum((X[i] - X)**2, axis=-1))\n",
    "\n",
    "def eucl_dist_matrix_thr_3(X):\n",
    "    X = np.array(X)\n",
    "    n = len(X)\n",
    "    # Initialize D as empty square list of lists, with len(x) rows/columns\n",
    "    D = np.zeros((n, n))\n",
    "    # Fill D with the actual pairwise distances\n",
    "    threads = []\n",
    "    for i in range(n):\n",
    "        t = Thread(target=task_3, args=(D, X, i))\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7616889959999753\n",
      "0.07967096500033222\n"
     ]
    }
   ],
   "source": [
    "X_rnd = random_dataset(500, 100)\n",
    "\n",
    "D_rnd = np.array(eucl_dist_matrix(X_rnd))\n",
    "D_rnd_thr_3 = eucl_dist_matrix_thr_3(X_rnd)\n",
    "assert np.allclose(D_rnd, D_rnd_thr_3)\n",
    "\n",
    "print(timeit(lambda: eucl_dist_matrix(X_rnd), number=1))\n",
    "print(timeit(lambda: eucl_dist_matrix_thr_3(X_rnd), number=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we can do better. The threads here are still too lightweight. If we add more workload to each thread, and reduce the number of threads, we get a better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Task to be run in parallel by each thread\n",
    "def task_4(D, X, i, chunk_size):\n",
    "    D[i:i+chunk_size] = cdist(X[i:i+chunk_size], X)\n",
    "    #cdist(X[i:i+chunk_size], X)\n",
    "\n",
    "def eucl_dist_matrix_thr_4(X, n_jobs=8):\n",
    "    X = np.array(X)\n",
    "    n = len(X)\n",
    "    # Initialize D as empty square list of lists, with len(x) rows/columns\n",
    "    D = np.zeros((n, n))\n",
    "    chunk_size = n // n_jobs\n",
    "    # Fill D with the actual pairwise distances\n",
    "    threads = []\n",
    "    for i in range(0, n, chunk_size):\n",
    "        t = Thread(target=task_4, args=(D, X, i, chunk_size))\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.657238543999483\n"
     ]
    }
   ],
   "source": [
    "X_rnd = random_dataset(10000, 100)\n",
    "\n",
    "#D_rnd_thr_3 = eucl_dist_matrix_thr_3(X_rnd)\n",
    "#D_rnd_thr_4 = eucl_dist_matrix_thr_4(X_rnd)\n",
    "#assert np.allclose(D_rnd_thr_3, D_rnd_thr_4)\n",
    "\n",
    "#print(timeit(lambda: eucl_dist_matrix_thr_3(X_rnd), number=1))\n",
    "print(timeit(lambda: eucl_dist_matrix_thr_4(X_rnd), number=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More code for comparison\n",
    "\n",
    "Below you can find versions without threads, and using `joblib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task to be run in parallel by each thread\n",
    "def task_4(D, X, i, chunk_size):\n",
    "    D[i:i+chunk_size] = cdist(X[i:i+chunk_size], X)\n",
    "\n",
    "def eucl_dist_matrix_4(X, n_jobs=8):\n",
    "    X = np.array(X)\n",
    "    n = len(X)\n",
    "    # Initialize D as empty square list of lists, with len(x) rows/columns\n",
    "    D = np.zeros((n, n))\n",
    "    chunk_size = n // n_jobs\n",
    "    # Fill D with the actual pairwise distances    \n",
    "    for i in range(0, n, chunk_size):\n",
    "        task_4(D, X, i, chunk_size)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.413308563999863\n",
      "25.02847582200002\n"
     ]
    }
   ],
   "source": [
    "X_rnd = random_dataset(15000, 100)\n",
    "\n",
    "#D_rnd_thr_4 = eucl_dist_matrix_thr_4(X_rnd)\n",
    "#D_rnd_4 = eucl_dist_matrix_4(X_rnd)\n",
    "#assert np.allclose(D_rnd_thr_4, D_rnd_4)\n",
    "\n",
    "print(timeit(lambda: eucl_dist_matrix_thr_4(X_rnd), number=1))\n",
    "print(timeit(lambda: eucl_dist_matrix_4(X_rnd), number=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Task to be run in parallel by each thread\n",
    "def task_jl(D, X, i, chunk_size):\n",
    "    return cdist(X[i:i+chunk_size], X)\n",
    "\n",
    "def eucl_dist_matrix_jl(X, n_jobs=8):\n",
    "    X = np.array(X)\n",
    "    n = len(X)\n",
    "    # Initialize D as empty square list of lists, with len(x) rows/columns\n",
    "    D = np.zeros((n, n))\n",
    "    chunk_size = n // n_jobs\n",
    "    # Fill D with the actual pairwise distances\n",
    "    p = Parallel(n_jobs=n_jobs, prefer='threads')\n",
    "    D = p(delayed(task_jl)(D, X, i, chunk_size) for i in range(0, n, chunk_size))\n",
    "    #print(D)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5781095169995751\n",
      "0.6651502690001507\n"
     ]
    }
   ],
   "source": [
    "X_rnd = random_dataset(6000, 100)\n",
    "\n",
    "#D_rnd_thr_4 = eucl_dist_matrix_thr_4(X_rnd)\n",
    "#D_rnd_4 = eucl_dist_matrix_4(X_rnd)\n",
    "#assert np.allclose(D_rnd_thr_4, D_rnd_4)\n",
    "\n",
    "print(timeit(lambda: eucl_dist_matrix_thr_4(X_rnd), number=1))\n",
    "print(timeit(lambda: eucl_dist_matrix_jl(X_rnd), number=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "**Process**, advantages:\n",
    "* Parallelizes any Python code\n",
    "\n",
    "**Process**, disadvantages:\n",
    "* Slow to start\n",
    "* Hard to communicate with\n",
    "\n",
    "**Threads**, advantages:\n",
    "* Lightweight, cheap to start (but not free)\n",
    "* Easy to communicate with\n",
    "\n",
    "**Threads**, disadvantages:\n",
    "* Only parallelizes code that releases the GIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
